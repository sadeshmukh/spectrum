import { writeFile, readFile, unlink } from "fs/promises";
import { join, dirname } from "path";
import { fileURLToPath } from "url";
import { spawn } from "child_process";
import { rewriteTitles } from "./lib/title-rewriter";
import { writeFileSync, readFileSync, existsSync } from "fs";

interface ScrapedItem {
  link: string;
  photoUrl: string | undefined;
  title: string | undefined;
  actualPrice: number | undefined;
}

interface PopulateScript {
  name: string;
  file: string;
  enabled: boolean;
}

const POPULATE_SCRIPTS: PopulateScript[] = [
  {
    name: "mock",
    file: "mock-populate.ts",
    enabled: true,
  },
  {
    name: "dummyjson",
    file: "dummyjson-populate.ts",
    enabled: true,
  },
  {
    name: "fakestore",
    file: "fakestore-populate.ts",
    enabled: true,
  },
  {
    name: "bestbuy",
    file: "bestbuy-populate.ts",
    enabled: false,
  },
  {
    name: "amazon",
    file: "amazon-populate.ts",
    enabled: false,
  },
];

async function runScript(script: PopulateScript): Promise<ScrapedItem[]> {
  return new Promise((resolve, reject) => {
    console.log(`\nRunning ${script.name} populate script...`);

    const scriptPath = join(
      dirname(fileURLToPath(import.meta.url)),
      script.file
    );
    const tempOutputPath = join(
      dirname(fileURLToPath(import.meta.url)),
      "..",
      "db",
      `scraped-items-${script.name}.ts`
    );

    const child = spawn("npx", ["tsx", scriptPath], {
      stdio: ["inherit", "pipe", "pipe"],
      cwd: dirname(fileURLToPath(import.meta.url)),
      env: { ...process.env, SCRAPED_ITEMS_OUTPUT: tempOutputPath },
    });

    let stdout = "";
    let stderr = "";

    child.stdout?.on("data", (data) => {
      stdout += data.toString();
      process.stdout.write(data);
    });

    child.stderr?.on("data", (data) => {
      stderr += data.toString();
      process.stderr.write(data);
    });

    child.on("close", async (code) => {
      if (code === 0) {
        console.log(`${script.name} script completed successfully`);
        try {
          const items = await readScrapedItemsFromFile(tempOutputPath);
          await cleanupTempFile(tempOutputPath);
          resolve(items);
        } catch (error) {
          console.error(`Failed to read items from ${script.name}:`, error);
          await cleanupTempFile(tempOutputPath);
          resolve([]);
        }
      } else {
        console.error(`${script.name} script failed with code ${code}`);
        if (stderr) {
          console.error(`Error output: ${stderr}`);
        }
        await cleanupTempFile(tempOutputPath);
        reject(new Error(`${script.name} script failed with code ${code}`));
      }
    });

    child.on("error", async (error) => {
      console.error(`Failed to start ${script.name} script:`, error);
      await cleanupTempFile(tempOutputPath);
      reject(error);
    });
  });
}

async function readScrapedItemsFromFile(
  filePath: string
): Promise<ScrapedItem[]> {
  try {
    const content = await readFile(filePath, "utf-8");

    const match = content.match(
      /export const scrapedItems = (\[[\s\S]*?\]) as const;/
    );
    if (match) {
      return JSON.parse(match[1]);
    }

    return [];
  } catch (error) {
    console.error(`Failed to read scraped items from ${filePath}:`, error);
    return [];
  }
}

async function cleanupTempFile(filePath: string) {
  try {
    await unlink(filePath);
  } catch (error) {
    console.error(`Failed to cleanup temp file ${filePath}:`, error);
  }
}

async function writeAggregatedData(items: ScrapedItem[]) {
  const validItems = items.filter((item) => {
    const isValid = item.title && item.actualPrice && item.actualPrice > 0;
    return isValid;
  });

  const outputPath = join(
    dirname(fileURLToPath(import.meta.url)),
    "..",
    "db",
    "scraped-items.ts"
  );

  const fileContent = `// This file is auto-generated by scripts/aggregate-populate.ts

export const scrapedItems = ${JSON.stringify(validItems, null, 2)} as const;
`;

  await writeFile(outputPath, fileContent, "utf-8");
  console.log(`\nWrote ${validItems.length} valid items to ${outputPath}`);
}

async function main() {
  try {
    console.log("Starting aggregated product collection...\n");

    const enabledScripts = POPULATE_SCRIPTS.filter((script) => script.enabled);

    if (enabledScripts.length === 0) {
      console.log(
        "No scripts are enabled. Please enable at least one script in the POPULATE_SCRIPTS array."
      );
      return;
    }

    const allItems: ScrapedItem[] = [];
    const stats = { success: 0, failure: 0 };

    for (const script of enabledScripts) {
      try {
        const items = await runScript(script);
        allItems.push(...items);
        stats.success += items.length;

        console.log(`${script.name} contributed ${items.length} items`);
      } catch (error) {
        console.error(`Failed to run ${script.name} script:`, error);
        stats.failure++;
      }
    }

    if (allItems.length === 0) {
      throw new Error("No items were collected from any script");
    }

    console.log(`\nRewriting titles for ${allItems.length} items...`);
    await rewriteTitles(allItems);

    await writeAggregatedData(allItems);

    console.log("\nAggregated product collection completed successfully!");
    console.log(
      `Summary: ${stats.success} items collected, ${stats.failure} script failures`
    );
  } catch (error) {
    console.error("=== Fatal Error ===");
    console.error(error);
    process.exit(1);
  }
}

if (import.meta.url === `file://${process.argv[1]}`) {
  main().catch((error) => {
    console.error("=== Unhandled Error ===");
    console.error(error);
    process.exit(1);
  });
}
